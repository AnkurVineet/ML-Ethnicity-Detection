{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Part\n",
    "\n",
    "Preprocessing part can be skipped as the output of this part is available in form of npy files:\n",
    "1) truncated_X_full.npy\n",
    "2) truncated_Y_full.npy\n",
    "These files are directly used in training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23705,)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "\n",
    "#Directory of \"UTK Face\" - Aligned and cropped Faces Dataset https://susanqq.github.io/UTKFace/ \n",
    "path = \"/home/FDUSER/Downloads/UTKFace/\"\n",
    "dirs = os.listdir( path )\n",
    "Y_data = []\n",
    "X_data = []\n",
    "\n",
    "#Resizing image from 200*200 to 100*100\n",
    "def resize():\n",
    "    for item in dirs:\n",
    "        if os.path.isfile(path+item):\n",
    "            f, e = os.path.splitext(path+item)\n",
    "            itemname, e = os.path.splitext(item);\n",
    "            race = itemname.split('_');   # Extracting Ethnicity tag from image name\n",
    "            Y_data.append(race[2]);       # Y_data contains encoded label of ethnic group of corresponding image.\n",
    "            #print(item)\n",
    "            im = Image.open(path+item)\n",
    "            imResize = im.resize((100,100), Image.ANTIALIAS)\n",
    "            imResize.save(  path+'resized/'+ itemname+ '.jpg', 'JPEG', quality=90)\n",
    "            image = cv2.imread (path+'resized/'+item)        #Storing resized images in new folder\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)   #Converting to RGB color mode\n",
    "            X_data.append (image)         #X_data contains image in form of 100*100*3 matrix.\n",
    "           \n",
    "resize()\n",
    "Y_data = np.array(Y_data,dtype='uint16')\n",
    "Y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23705, 100, 100, 3)\n",
      "(23705,)\n"
     ]
    }
   ],
   "source": [
    "# Initially dataset has 23705 images of size 100*100 in RGB format\n",
    "X_data = np.array(X_data)\n",
    "print(X_data.shape)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('face_Y_full.npy', Y_data)\n",
    "np.save('face_X_full.npy', X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[    0     1     2     3     4]\n",
      " [10078  4526  3434  3975  1692]]\n"
     ]
    }
   ],
   "source": [
    "# But dataset contains more images from ethnic group:'0' i.e. White. So we need to equalize this number near to\n",
    "# number of images in other ethnic groups\n",
    "unique_elements, counts_elements = np.unique(Y_data, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting all the index of white ethnic group in Y_data i.e '0'.\n",
    "del_list = []\n",
    "for i in range(Y_data.shape[0]):\n",
    "    if(Y_data[i] == 0):\n",
    "        del_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rand_list = random.sample(del_list, 6500)  # Randomly selecting 6500 instances to be deleted from all the images of white ethnic group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list = np.array(rand_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6500,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14372,  8988, 21962, ...,  4835,  6046,  9054])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_re_data = np.reshape(X_data, (23705,30000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = np.delete(X_re_data, rand_list,0)\n",
    "#Y_list = np.delete(Y_data, rand_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17205, 30000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After Deleting 17205 instances are left same is to be done with Y_list\n",
    "X_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[   0    1    2    3    4]\n",
      " [3578 4526 3434 3975 1692]]\n"
     ]
    }
   ],
   "source": [
    "del_list = []\n",
    "for i in range(Y_data.shape[0]):\n",
    "    if(Y_data[i] == 0):\n",
    "        del_list.append(i)\n",
    "        \n",
    "import random\n",
    "\n",
    "rand_list = np.array(rand_list)\n",
    "rand_list = random.sample(del_list, 6500)\n",
    "X_list = np.delete(X_re_data, rand_list,0)\n",
    "#Y_list = np.delete(Y_data, rand_list)\n",
    "\n",
    "# After deleting we have images of all the ethnic groups in comparable numbers.\n",
    "unique_elements, counts_elements = np.unique(Y_list, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the lists in npy file\n",
    "np.save('truncated_X_full.npy', X_list)\n",
    "np.save('truncated_Y_full.npy', Y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Part - Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We directly used the list it can also be loaded as\n",
    "# X_list = np.load(\"truncated_X_full.npy\")\n",
    "X_list = np.reshape(X_list, (17205,100,100,3))   # Reshape in 100*100*3 matrix form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_list, Y_list, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "batch_size = 32\n",
    "num_classes = 5\n",
    "epochs = 20\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_FACERACE_trained_model.h5'    # Name of the model to be saved\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecture Used is similar to VGG-16\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "Train on 12903 samples, validate on 4302 samples\n",
      "Epoch 1/25\n",
      "12903/12903 [==============================] - 895s 69ms/step - loss: 1.5028 - acc: 0.3354 - val_loss: 1.4859 - val_acc: 0.3756\n",
      "Epoch 2/25\n",
      "12903/12903 [==============================] - 684s 53ms/step - loss: 1.2742 - acc: 0.4988 - val_loss: 1.3400 - val_acc: 0.4891\n",
      "Epoch 3/25\n",
      "12903/12903 [==============================] - 655s 51ms/step - loss: 1.1036 - acc: 0.5837 - val_loss: 1.0275 - val_acc: 0.6223\n",
      "Epoch 4/25\n",
      "12903/12903 [==============================] - 659s 51ms/step - loss: 0.9910 - acc: 0.6350 - val_loss: 0.9331 - val_acc: 0.6643\n",
      "Epoch 5/25\n",
      "12903/12903 [==============================] - 658s 51ms/step - loss: 0.9151 - acc: 0.6674 - val_loss: 1.0285 - val_acc: 0.6065\n",
      "Epoch 6/25\n",
      "12903/12903 [==============================] - 668s 52ms/step - loss: 0.8740 - acc: 0.6819 - val_loss: 0.9462 - val_acc: 0.6499\n",
      "Epoch 7/25\n",
      "12903/12903 [==============================] - 657s 51ms/step - loss: 0.8291 - acc: 0.7015 - val_loss: 0.8210 - val_acc: 0.7104\n",
      "Epoch 8/25\n",
      "12903/12903 [==============================] - 658s 51ms/step - loss: 0.7959 - acc: 0.7150 - val_loss: 0.8293 - val_acc: 0.7025\n",
      "Epoch 9/25\n",
      "12903/12903 [==============================] - 659s 51ms/step - loss: 0.7668 - acc: 0.7274 - val_loss: 0.7971 - val_acc: 0.7190\n",
      "Epoch 10/25\n",
      "12903/12903 [==============================] - 660s 51ms/step - loss: 0.7446 - acc: 0.7333 - val_loss: 0.8322 - val_acc: 0.7022\n",
      "Epoch 11/25\n",
      "12903/12903 [==============================] - 660s 51ms/step - loss: 0.7161 - acc: 0.7465 - val_loss: 0.7712 - val_acc: 0.7278\n",
      "Epoch 12/25\n",
      "12903/12903 [==============================] - 660s 51ms/step - loss: 0.6860 - acc: 0.7553 - val_loss: 0.7893 - val_acc: 0.7271\n",
      "Epoch 13/25\n",
      "12903/12903 [==============================] - 661s 51ms/step - loss: 0.6638 - acc: 0.7659 - val_loss: 0.7581 - val_acc: 0.7366\n",
      "Epoch 14/25\n",
      "12903/12903 [==============================] - 661s 51ms/step - loss: 0.6459 - acc: 0.7694 - val_loss: 0.8392 - val_acc: 0.7234\n",
      "Epoch 15/25\n",
      "12903/12903 [==============================] - 661s 51ms/step - loss: 0.6303 - acc: 0.7772 - val_loss: 0.7888 - val_acc: 0.7276\n",
      "Epoch 16/25\n",
      "12903/12903 [==============================] - 665s 52ms/step - loss: 0.6058 - acc: 0.7849 - val_loss: 0.6896 - val_acc: 0.7624\n",
      "Epoch 17/25\n",
      "12903/12903 [==============================] - 668s 52ms/step - loss: 0.5891 - acc: 0.7936 - val_loss: 0.7675 - val_acc: 0.7536\n",
      "Epoch 18/25\n",
      "12903/12903 [==============================] - 665s 52ms/step - loss: 0.5690 - acc: 0.7995 - val_loss: 0.7314 - val_acc: 0.7566\n",
      "Epoch 19/25\n",
      "12903/12903 [==============================] - 662s 51ms/step - loss: 0.5492 - acc: 0.8038 - val_loss: 0.6664 - val_acc: 0.7727\n",
      "Epoch 20/25\n",
      "12903/12903 [==============================] - 661s 51ms/step - loss: 0.5376 - acc: 0.8110 - val_loss: 0.6907 - val_acc: 0.7664\n",
      "Epoch 21/25\n",
      "12903/12903 [==============================] - 663s 51ms/step - loss: 0.5147 - acc: 0.8176 - val_loss: 0.6924 - val_acc: 0.7592\n",
      "Epoch 22/25\n",
      "12903/12903 [==============================] - 662s 51ms/step - loss: 0.4986 - acc: 0.8221 - val_loss: 0.7100 - val_acc: 0.7497\n",
      "Epoch 23/25\n",
      "12903/12903 [==============================] - 661s 51ms/step - loss: 0.4871 - acc: 0.8294 - val_loss: 0.6803 - val_acc: 0.7771\n",
      "Epoch 24/25\n",
      "12903/12903 [==============================] - 663s 51ms/step - loss: 0.4754 - acc: 0.8327 - val_loss: 0.7063 - val_acc: 0.7689\n",
      "Epoch 25/25\n",
      "12903/12903 [==============================] - 662s 51ms/step - loss: 0.4543 - acc: 0.8403 - val_loss: 0.7222 - val_acc: 0.7710\n",
      "Saved trained model at /home/FDUSER/Downloads/ML/saved_models/keras_FACERACE_trained_model.h5 \n",
      "4302/4302 [==============================] - 64s 15ms/step\n",
      "Test loss: 0.7221517877099903\n",
      "Test accuracy: 0.7710367271590931\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "x_train = X_train\n",
    "x_test = X_test\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=25,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    model.save(model_path)\n",
    "    print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
